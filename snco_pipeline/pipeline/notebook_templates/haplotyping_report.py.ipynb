{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# snakemake preamble inserted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from snco import MarkerRecords, PredictionRecords\n",
    "from snco.records import NestedData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d9207b",
   "metadata": {},
   "source": [
    "### Report for analysis of {{ snakemake.wildcards[\"dataset_name\"] }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = MarkerRecords.read_json(snakemake.input.markers)\n",
    "markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "haplotypes = PredictionRecords.read_json(snakemake.input.preds)\n",
    "haplotypes.add_metadata(\n",
    "    total_marker_count=NestedData(\n",
    "        ['cb'], int, {cb: int(markers.total_marker_count(cb)) for cb in markers.barcodes}\n",
    "    )\n",
    ")\n",
    "haplotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96548ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_stats = pd.read_csv(snakemake.input.stats, sep='\\t', index_col='cb')\n",
    "cb_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64476a1",
   "metadata": {},
   "source": [
    "## Number of informative reads\n",
    "\n",
    "The number of reads that distinguish haplotypes is dependent on the sequencing stragety, library complexity, and sequencing depth, as well as the number of (mappable) SNPs that actually distinguish the two haplotypes. This dataset has already been filtered to remove barcodes with fewer than {{ snakemake.config[\"haplotyping\"][\"preprocessing\"][\"min_informative_reads_per_barcode\"] }} informative reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_counts = [markers.total_marker_count(cb) for cb in markers.barcodes]\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    marker_counts,\n",
    "    bins=np.logspace(np.log10(min(marker_counts)), np.log10(max(marker_counts)), 25),\n",
    ")\n",
    "plt.xscale('log')\n",
    "ax.set_xlabel('Number of informative reads (log10 scale)')\n",
    "ax.set_ylabel('Number of barcodes/samples')\n",
    "ax.set_title(f'{snakemake.wildcards.dataset_name} informative read distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c36bc",
   "metadata": {},
   "source": [
    "Sparsely sequenced nuclei will have fewer estimated crossovers due to failure to detect some, especially at chromosome ends. Nuclei with large numbers of reads and large crossover estimates likely represent doublets. We can use the scatterplot of crossover rate vs read number to estimate a suitable threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f5c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(figsize=(8, 8))\n",
    "ax = sns.regplot(\n",
    "    x=10 ** cb_stats.co_n_marker_reads,\n",
    "    y=cb_stats.n_crossovers,\n",
    "    data=cb_stats,\n",
    "    scatter_kws=dict(alpha=0.05),\n",
    "    line_kws=dict(color='#252525'),\n",
    "    lowess=True,\n",
    "    ax=ax\n",
    ")\n",
    "plt.xscale('log')\n",
    "ax.set_xlabel('Number of informative reads (log10 scale)')\n",
    "ax.set_ylabel('Estimated Crossovers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0310bed",
   "metadata": {},
   "source": [
    "## Doublet probabilities\n",
    "\n",
    "`snco` performs doublet detection for single cell datasets using \"synthetic doublets\", created by mixing multiple barcodes together. Several summary statistics are calculated and the K-nearest neighbours classification is used to produce a score (for real data vs synthetic doublets). The choice of filtering threshold to remove doublets can vary with dataset/application and is left up to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144194cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a threshold for removing sparsely sequenced nuclei here\n",
    "non_sparse_haplotypes = haplotypes.query('total_marker_count > 300')\n",
    "non_sparse_markers = markers.filter(non_sparse_haplotypes.barcodes, inplace=False)\n",
    "\n",
    "\n",
    "def qcutter(q, doublet_probs):\n",
    "    x = np.asarray(list(doublet_probs.values()))\n",
    "    quantiles = np.linspace(0, 100, q + 1)\n",
    "    bins = np.percentile(x, quantiles)\n",
    "    bins[0] -= 1e-8  # ensure inclusion of min value\n",
    "    labels = [f'[{bins[i]:.2f}, {bins[i+1]:.2f}]' for i in range(q)]\n",
    "    def _wrapped(cb):\n",
    "        i = np.digitize(doublet_probs[cb], bins[1:-1], right=True)\n",
    "        return labels[i]\n",
    "    return _wrapped\n",
    "\n",
    "if hasattr(non_sparse_haplotypes, 'doublet_probability'):\n",
    "    plt.hist(\n",
    "        list(non_sparse_haplotypes.doublet_probability.values()),\n",
    "        bins=25, range=(0, 1),\n",
    "    )\n",
    "    plt.show()\n",
    "    quantile_separated_barcodes = dict(non_sparse_markers.groupby(qcutter(5, non_sparse_haplotypes.doublet_probability)))\n",
    "    for i, q in enumerate(sorted(quantile_separated_barcodes)):\n",
    "        markers_group = quantile_separated_barcodes[q]\n",
    "        cb = np.random.choice(markers_group.barcodes)\n",
    "        fig, axes = markers_group.plot_barcode(cb, co_preds=non_sparse_haplotypes, max_yheight=10, figsize=(12, 3))\n",
    "        fig.suptitle(f'Doublet probability q{i+1} {q} example barcode')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdfbd7a",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "You can create your own quality control filters here - this is just an example that is generally suitable for 10x RNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153dffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(non_sparse_haplotypes, 'doublet_probability'):\n",
    "    haplotypes_filt = haplotypes.query('(doublet_probability < 0.25) & (total_marker_count > 300)')\n",
    "else:\n",
    "    haplotypes_filt = haplotypes.query('total_marker_count > 300')\n",
    "markers_filt = markers.filter(haplotypes_filt.barcodes, inplace=False)\n",
    "cb_stats_filt = cb_stats.loc[haplotypes_filt.barcodes].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f460a0b",
   "metadata": {},
   "source": [
    "### Segregation distortion\n",
    "\n",
    "We can plot the overall allele frequencies of the dataset to look for single locus distortions (these can sometimes be affected by noise in the data, if you see weird/extreme patterns then perhaps stricter data cleaning/filtering is required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60926bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "haplotypes_filt.plot_allele_ratio()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2258b",
   "metadata": {},
   "source": [
    "### Crossover distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(cb_stats_filt.n_crossovers, bins=20)\n",
    "ax.set_xlabel('Estimated crossovers')\n",
    "ax.set_ylabel('Number of barcodes/samples')\n",
    "ax.set_title(f'{snakemake.wildcards.dataset_name} estimated crossover numbers')\n",
    "plt.show()\n",
    "\n",
    "haplotypes_filt.plot_recombination_landscape(co_markers=markers_filt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89ced5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
